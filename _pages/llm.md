---
layout: page
title: "LLM Projects"
---

<div class="project-card">
  <div class="project-card-content">
    <h3>Git Issue Bot</h3>
      <img src="https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white" alt="Python"><img src="https://img.shields.io/badge/LangChain-121212?style=flat&logo=chainlink&logoColor=white" alt="LangChain"><img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=flat&logo=Streamlit&logoColor=white" alt="Streamlit"><img src="https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white" alt="Docker"><img src="https://img.shields.io/badge/PostgreSQL-316192?style=flat&logo=postgresql&logoColor=white" alt="PostgreSQL">
      <ul>
        <li>Engineered an intelligent chatbot leveraging OpenAI's API to dynamically search GitHub repositories and issues.</li>
        <li>Architected a robust conversational system using LangChain framework, implementing custom tools and chains for relevant context-aware responses and improved search accuracy.</li>
        <li>Designed and implemented a PostgreSQL database system for efficient management of user interactions, chat histories, and personalized repository and issue bookmarking.</li>
        <li>Developed a containerized full-stack application using Streamlit for the frontend interface, ensuring seamless deployment and scalability through Docker.</li>
      </ul>
      <p><a href="https://github.com/Billa-Man/git-issue-bot">View Project</a></p>
  </div>
  <img src="/assets/projects/chatbot.png" alt="git-issue-bot" class="project-card-img" />
</div>

<div class="project-card">
  <div class="project-card-content">
    <h3>Prompt2Program</h3>
      <img src="https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white" alt="Python"><img src="https://img.shields.io/badge/LangChain-121212?style=flat&logo=chainlink&logoColor=white" alt="LangChain"><img src="https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white" alt="Docker"><img src="https://img.shields.io/badge/Hugging%20Face-FFD21E?style=flat&logo=huggingface&logoColor=black" alt="HuggingFace"><img src="https://img.shields.io/badge/MongoDB-47A248?style=flat&logo=mongodb&logoColor=white" alt="MongoDB"><img src="https://img.shields.io/badge/Qdrant-FF4F64.svg?style=flat&logo=qdrant&logoColor=white" alt="Qdrant">
      <ul>
        <li>Implemented a RAG system to assist software developers, enabling domain-specific query responses for coding tasks.</li>
        <li>Created an ETL pipeline using ClearML to ingest and process data from C++ and Python documentations, storing raw data in MongoDB and vectorized representations in Qdrant.</li>
        <li>Fine-tuned LLaMa 3.2 3b by implementing LoRA (Low-Rank Adaptation) on a custom preference dataset generated using chatGPT API.</li>
        <li>Deployed a Gradio-based application with Huggingface Hub and Ollama integration for code generation instructions. Utilized Open WebUI for an enhanced user interface and improved interaction with the LLM model.</li>
      </ul>
      <p><a href="https://github.com/Billa-Man/prompt2program">View Project</a></p>
  </div>
  <img src="/assets/projects/p2p.png" alt="p2p" class="project-card-img" />
</div>

<div class="project-card">
  <div class="project-card-content">
    <h3>LLM Prompt Recovery</h3>
      <img src="https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white" alt="Python"><img src="https://img.shields.io/badge/Hugging%20Face-FFD21E?style=flat&logo=huggingface&logoColor=black" alt="HuggingFace"><img src="https://img.shields.io/badge/Unsloth-FF6B6B?style=flat&logo=chainlink&logoColor=white" alt="Unsloth">
      <ul>
        <li>Developed and trained a Language Model (LLM) for prompt recovery using PyTorch and Unsloth framework, achieving 80.8% reduction in training loss from initial to final epoch.</li>
        <li>Implemented FastLanguageModel inference pipeline enabling 2x faster processing speeds for text transformation tasks.</li>
        <li>Engineered temperature-controlled text generation system (temperature = 1.5, min_p = 0.1) for consistent prompt recovery performance.</li>
        <li>Successfully deployed the optimized model to Hugging Face Hub, making it accessible for public use and research applications.</li>
      </ul>
      <p><a href="https://www.kaggle.com/code/sohithbandari/llama-3-2-3b-llm-prompt-recovery/">View Project</a></p>
  </div>
  <img src="/assets/projects/prompt_recovery.png" alt="prompt-recovery" class="project-card-img"/>
</div>